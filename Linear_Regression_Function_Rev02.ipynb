{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Linear_Regression_Function_Rev02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example from http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python Libraries to use in the code\n",
    "\n",
    "\n",
    "\n",
    "# General Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# System Interation\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# PLotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\") # Set Seaborn formatting style\n",
    "\n",
    "\n",
    "# Datetime functions\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "\n",
    "# Database\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_classification, make_multilabel_classification, make_regression\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, f_regression, mutual_info_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Score\n",
    "# Working\n",
    "\n",
    "def func_regression(func_df, func_target_name, func_k, func_poly, func_cv_splits):\n",
    "    \n",
    "    print(\"Parameters: K=\", func_k, \", Poly=\", func_poly, \", CV Splits=\", func_cv_splits)\n",
    "    print(\"\")\n",
    "    \n",
    "    # Data Prep ####################################################\n",
    "    \n",
    "    func_df = func_df.dropna() # Drop all NA values\n",
    "    func_df_numeric = func_df._get_numeric_data().copy() # Get all numeric columns from DF\n",
    "    \n",
    "    x_cols = list(func_df_numeric) # Define x cols\n",
    "    x_cols.remove(func_target_name) # remove target names from x col names\n",
    "    \n",
    "    \n",
    "    X = func_df_numeric[x_cols].values # create x df   \n",
    "\n",
    "    y = func_df_numeric[func_target_name].values # create y df\n",
    "    y = y.ravel() # Reshape y from (m, m) to (n, ) to allow for modelling\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Data Modelling ##################################################\n",
    "    \n",
    "    # Select 4 best parameters\n",
    "    X_SelectKBest = SelectKBest(f_regression, k=func_k).fit_transform(X, y)\n",
    "    \n",
    "    X_fit = SelectKBest(f_regression, k=func_k).fit(X, y)\n",
    "    func_arr_scores = pd.DataFrame(list(zip(list(func_df[x_cols]), list(X_fit.scores_))), columns=['col_name', 'col_score'])\n",
    "    \n",
    "    \n",
    "    # Build Polynomical DF\n",
    "    poly = PolynomialFeatures(degree=func_poly)\n",
    "    X_SelectKBest_Poly = poly.fit_transform(X_SelectKBest)\n",
    "    \n",
    "    # Train Model\n",
    "    clf = linear_model.LinearRegression()\n",
    "    \n",
    "    \n",
    "    # Perform n-fold cross validation\n",
    "    scores = cross_val_score(clf, X_SelectKBest_Poly, y)\n",
    "    # scoring =\n",
    "    print(\"CV MAE Scores (Avg): \", abs(round(np.mean(scores), 4)))\n",
    "    print(\"\")\n",
    "    print(\"CV MAE Scores (Avg): \", abs(np.round(scores, 4)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Predict Using Model ######################################################\n",
    "    \n",
    "    # Predict Scores\n",
    "    clf.fit(X_SelectKBest_Poly, y)\n",
    "    y_predicted = clf.predict(X_SelectKBest_Poly)\n",
    "    \n",
    "    \n",
    "    # Add predicted columns to the df    \n",
    "    func_df.insert(func_df.shape[1], func_target_name+'_pred', y_predicted)\n",
    "    \n",
    "     \n",
    "    \n",
    "    # Print Coefficients #########################################################\n",
    "    \n",
    "    lst_featutes = list(func_df_numeric[x_cols].columns[list(X_fit.get_support())])\n",
    "    lst_params = poly.get_feature_names()\n",
    "    lst_coefs = clf.coef_\n",
    "    var_intercept = clf.intercept_\n",
    "    \n",
    "    for counter, name in enumerate(lst_featutes):\n",
    "        \n",
    "        lst_params = [item.replace(\"x\"+str(counter), str(name)) for item in lst_params]\n",
    "        \n",
    "    lst_final = list(zip(lst_params, lst_coefs))\n",
    "    \n",
    "    print('')\n",
    "    print('Intercept:', var_intercept)\n",
    "    print('')\n",
    "    print('Coefficients')\n",
    "    print(pd.DataFrame(lst_final, columns=['param', 'coef']))\n",
    "    \n",
    "    \n",
    "    # Print Errors #########################################################\n",
    "    var_mae = mean_absolute_error(func_df['target'], func_df['target_pred'])\n",
    "    print('')\n",
    "    print('Print Errors')\n",
    "    \n",
    "    \n",
    "    print('')\n",
    "    var_mae = mean_absolute_error(func_df['target'], func_df['target_pred'])\n",
    "    print('MAE (Mean Absolute Error):', round(var_mae, 4))\n",
    "    \n",
    "    \n",
    "    var_mse = mean_squared_error(func_df['target'], func_df['target_pred'])\n",
    "    print('MAE (Mean Absolute Error):', round(var_mse, 4))\n",
    "    \n",
    "\n",
    "    var_r2_error = r2_score(func_df['target'], func_df['target_pred'])\n",
    "    print('R2 Error:', round(var_r2_error,4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # The standard error of the regression provides the absolute measure of the typical distance that the data points fall from the regression line. S is in the units of the dependent variable.\n",
    "\n",
    "\n",
    "    # R-squared provides the relative measure of the percentage of the dependent variable variance that the model explains. R-squared can range from 0 to 100%.\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return func_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Test Data\n",
    "\n",
    "var_n_rows = 1000 # number of rows\n",
    "\n",
    "# Create regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=var_n_rows, n_features=10, n_informative=3, \n",
    "                               n_targets=1, tail_strength=0)\n",
    "\n",
    "# Convert data in pandas dataframe\n",
    "arr_test_data = pd.DataFrame(X_reg)\n",
    "\n",
    "\n",
    "# Introduce some randomness into the target\n",
    "# arr_test_data['target'] = y_reg\n",
    "\n",
    "arr_test_data['target'] = y_reg + np.random.rand(var_n_rows) * 131.32\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: K= 3 , Poly= 2 , CV Splits= 10\n",
      "\n",
      "CV MAE Scores (Avg):  0.7548\n",
      "\n",
      "CV MAE Scores (Avg):  [0.7441 0.7516 0.7688]\n",
      "\n",
      "Intercept: 65.48353516815948\n",
      "\n",
      "Coefficients\n",
      "  param       coef\n",
      "0     1   0.000000\n",
      "1     1  27.987604\n",
      "2     6  25.180953\n",
      "3     8  51.356795\n",
      "4   1^2  -0.817101\n",
      "5   1 6  -1.561236\n",
      "6   1 8   0.986759\n",
      "7   6^2   0.328101\n",
      "8   6 8  -0.297469\n",
      "9   8^2  -0.781924\n",
      "\n",
      "Print Errors\n",
      "\n",
      "MAE (Mean Absolute Error): 32.2796\n",
      "MAE (Mean Absolute Error): 1382.6029\n",
      "R2 Error: 0.7626\n"
     ]
    }
   ],
   "source": [
    "# func_regression(func_df, func_target_name, func_k, func_poly, func_cv_splits)\n",
    "\n",
    "# func_df = dataframe to predict\n",
    "# func_target_name = name of target in dataframe\n",
    "# func_k = select k most informative columns to use\n",
    "# func_poly = number of polynomials to use\n",
    "# func_cv_splits = number of cross-validation splits to use\n",
    "\n",
    "\n",
    "arr_data_output = func_regression(arr_test_data, 'target', 3, 2, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
